# üìö Pipeline d'Ingestion de Documents

Ce dossier contient le pipeline complet pour ing√©rer vos documents personnels (CV, LinkedIn, comp√©tences) dans la base vectorielle Qdrant.

## üéØ Objectif

Transformer vos documents textuels en vecteurs num√©riques (embeddings) pour permettre une recherche s√©mantique rapide et pertinente lors de la g√©n√©ration d'emails de candidature.

## üìã Flow Complet

```
Documents sources (PDF/Markdown)
        ‚Üì
    Extraction du texte
        ‚Üì
    Chunking (d√©coupage intelligent)
        ‚Üì
    G√©n√©ration d'embeddings (vectorisation)
        ‚Üì
    Stockage dans Qdrant
```

## üîß Composants

### 1. **pdf_processor.py** - Traitement des PDFs

**R√¥le** : Extraire et chunker le contenu des fichiers PDF.

**Fonctionnement** :
- Utilise `pymupdf4llm` pour extraire le texte en format Markdown
- Pr√©serve la structure (titres, paragraphes, listes)
- D√©l√®gue le chunking au `Chunker`

**Fichiers trait√©s** :
- `data/cv.pdf` ‚Üí CV du candidat
- `data/linkedin.pdf` ‚Üí Profil LinkedIn export√©

### 2. **markdown_processor.py** - Traitement des Markdown

**R√¥le** : Extraire et chunker le contenu des fichiers Markdown.

**Fonctionnement** :
- Lit directement le fichier `.md`
- D√©l√®gue le chunking au `Chunker`

**Fichiers trait√©s** :
- `data/dossier_competence.md` ‚Üí Comp√©tences d√©taill√©es
- `data/informations.md` ‚Üí Informations personnelles

### 3. **app/services/chunker.py** - D√©coupage Intelligent

**R√¥le** : D√©couper les documents en morceaux (chunks) de taille optimale.

**Pourquoi chunker ?**
- Les LLMs ont une limite de tokens
- Les petits chunks am√©liorent la pr√©cision de la recherche
- √âvite de perdre du contexte avec un d√©coupage trop petit

**Strat√©gie** :
- **Chunk Size** : 400 caract√®res (configurable via `CHUNK_SIZE`)
- **Overlap** : 50 caract√®res (configurable via `CHUNK_OVERLAP`)
- **S√©parateurs** : Markdown-aware (headers, paragraphes, listes)

**Exemple** :
```
Texte original (1000 chars)
    ‚Üì
Chunk 1 (0-400)
Chunk 2 (350-750)  ‚Üê 50 chars de chevauchement
Chunk 3 (700-1000)
```

**Avantages de l'overlap** :
- √âvite de couper les phrases importantes
- Maintient le contexte entre les chunks
- Am√©liore la qualit√© de la recherche

### 4. **app/services/embeddings.py** - G√©n√©ration d'Embeddings

**R√¥le** : Transformer le texte en vecteurs num√©riques.

**Mod√®le utilis√©** : `intfloat/multilingual-e5-base`
- **Type** : Sentence Transformer
- **Dimension** : 768
- **Langues** : Fran√ßais, Anglais, 100+ langues
- **Sp√©cialit√©** : Recherche s√©mantique multilingue

**Fonctionnement** :
```python
texte = "D√©veloppeur Python avec 5 ans d'exp√©rience"
    ‚Üì
embedding = [0.123, -0.456, 0.789, ..., 0.321]  # 768 dimensions
```

**Pourquoi des embeddings ?**
- Capture le **sens** du texte, pas juste les mots
- Permet la recherche s√©mantique : "dev python" ‚âà "d√©veloppeur Python"
- Les vecteurs similaires sont proches dans l'espace vectoriel

### 5. **app/services/qdrant_service.py** - Stockage Vectoriel

**R√¥le** : G√©rer la base de donn√©es vectorielle Qdrant.

**Collection** : `user_info`
- **Dimension** : 768 (correspond au mod√®le d'embeddings)
- **Distance** : COSINE (mesure la similarit√© angulaire)
- **IDs** : Entiers auto-g√©n√©r√©s (0, 1, 2, ...)

**Structure d'un point** :
```json
{
  "id": 42,
  "vector": [0.123, -0.456, ..., 0.321],
  "payload": {
    "text": "D√©veloppeur Python avec 5 ans d'exp√©rience",
    "source": "cv.pdf",
    "chunk_index": 5
  }
}
```

**Op√©rations** :
- `ensure_collection()` : Cr√©e la collection si elle n'existe pas
- `upsert_documents()` : Ins√®re/Met √† jour les documents
- `search()` : Recherche par similarit√© vectorielle

### 6. **ingestion_pipeline.py** - Orchestrateur

**R√¥le** : Coordonner tout le processus d'ingestion.

**√âtapes** :
1. **Validation** : V√©rifie que le dossier `data/` existe
2. **Traitement** :
   - PDF ‚Üí chunks
   - Markdown ‚Üí chunks
3. **Collection** : Rassemble tous les chunks
4. **Vectorisation** : G√©n√®re les embeddings
5. **Stockage** : Ins√®re dans Qdrant

**M√©tadonn√©es ajout√©es** :
- `source` : Nom du fichier source
- `chunk_index` : Position du chunk dans le document
- `text` : Contenu textuel du chunk

## üöÄ Utilisation

### Pr√©requis

1. **Pr√©parer vos fichiers dans `data/`** :
```
backend/data/
‚îú‚îÄ‚îÄ cv.pdf
‚îú‚îÄ‚îÄ linkedin.pdf
‚îú‚îÄ‚îÄ dossier_competence.md
‚îî‚îÄ‚îÄ informations.md
```

2. **Configurer le `.env`** :
```env
# Qdrant (local ou cloud)
QDRANT_URL=https://your-cluster.qdrant.io:6333
QDRANT_API_KEY=your_api_key
QDRANT_COLLECTION=user_info

# Chunking
CHUNK_SIZE=400
CHUNK_OVERLAP=50

# Embeddings (sentence-transformers local)
EMBEDDING_MODEL=intfloat/multilingual-e5-base
```

### Lancer l'ingestion

```bash
cd backend
python scripts/ingest_data.py
```

### R√©sultat attendu

```
‚úÖ Documents trait√©s : 100 chunks
   - cv.pdf : 19 chunks
   - linkedin.pdf : 45 chunks
   - dossier_competence.md : 21 chunks
   - informations.md : 15 chunks

‚úÖ Embeddings g√©n√©r√©s : 100 vecteurs (768 dimensions)
‚úÖ Stock√©s dans Qdrant : collection 'user_info'
```

## üîç Recherche S√©mantique (apr√®s ingestion)

Une fois les donn√©es ing√©r√©es, vous pouvez faire des recherches :

```python
from app.services.qdrant_service import get_qdrant_service

qdrant = get_qdrant_service()

# Recherche s√©mantique
results = qdrant.search(
    query="exp√©rience en Python et FastAPI",
    limit=5,
    score_threshold=0.7
)

# Retourne les 5 chunks les plus pertinents
for result in results:
    print(f"Score: {result['score']}")
    print(f"Text: {result['text']}")
    print(f"Source: {result['source']}")
```

## üõ†Ô∏è Configuration Avanc√©e

### Ajuster le chunking

**Chunks plus grands** (meilleur contexte, moins pr√©cis) :
```env
CHUNK_SIZE=800
CHUNK_OVERLAP=100
```

**Chunks plus petits** (plus pr√©cis, moins de contexte) :
```env
CHUNK_SIZE=200
CHUNK_OVERLAP=25
```

### Changer le mod√®le d'embeddings

**Mod√®le plus performant** (plus lourd) :
```env
EMBEDDING_MODEL=intfloat/multilingual-e5-large  # 1024 dimensions
```

‚ö†Ô∏è Si vous changez de mod√®le, **recr√©ez la collection** :
```python
self.qdrant.ensure_collection(recreate=True)
```

### Recr√©er la collection

Si vous avez une erreur de dimension :
```
Vector dimension error: expected dim: X, got Y
```

Modifiez `ingestion_pipeline.py` :
```python
self.qdrant.ensure_collection(recreate=True)
```

## üìä Monitoring

### Logs structur√©s

Le pipeline log chaque √©tape en JSON :
```json
{"event": "pdf_chunked", "file": "cv.pdf", "chunks": 19}
{"event": "embedding_texts", "count": 100}
{"event": "documents_upserted", "count": 100}
```

### V√©rifier Qdrant

Via l'API REST :
```bash
curl $QDRANT_URL/collections/user_info
```

Via le Dashboard Qdrant (si cluster cloud) :
- https://cloud.qdrant.io

## üêõ Troubleshooting

### Erreur "collection not found"

```bash
# Recr√©er la collection
python scripts/ingest_data.py
```

### Erreur "dimension mismatch"

Chang√© de mod√®le d'embeddings ? Recr√©ez la collection :
```python
self.qdrant.ensure_collection(recreate=True)
```

### Erreur "file not found"

V√©rifiez que vos fichiers sont dans `backend/data/` :
```bash
ls -la data/
```

### Performance lente

Le t√©l√©chargement du mod√®le sentence-transformers la premi√®re fois peut prendre du temps (~250MB).

Cache du mod√®le : `~/.cache/huggingface/`

## üìà Prochaines √âtapes

1. **RAG Pipeline** : Utiliser ces embeddings pour la g√©n√©ration d'emails
2. **Reranking** : Affiner les r√©sultats de recherche
3. **Mise √† jour** : Ajouter des documents sans tout r√©-ing√©rer
4. **Versioning** : G√©rer plusieurs versions de vos documents

## üîó Liens Utiles

- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [Sentence Transformers](https://www.sbert.net/)
- [LangChain Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/)
