# Configuration LLM par agent
# Chaque agent peut utiliser n'importe quel provider (OpenAI, Google, Anthropic, etc.)
# Format: provider + model + paramètres spécifiques
#
# Surcharge via ENV : AGENT_<AGENT_NAME>_<PARAM>=value
# Exemples:
#   AGENT_ANALYZER_PROVIDER=anthropic
#   AGENT_ANALYZER_MODEL=claude-3-5-sonnet-20241022
#   AGENT_ANALYZER_TEMPERATURE=0.2
#   AGENT_EMAIL_WRITER_MAX_TOKENS=800

agents:
  # Analyzer - Extraction et analyse d'offres
  analyzer:
    provider: openai
    model: gpt-4o-mini
    temperature: 0.2 # Réduction de la créativité, plus déterministe
    top_p: 0.85 # Suffisant pour cohérence lexicale
    frequency_penalty: 0.4 # Évite répétitions sur les mêmes termes (stack, missions)
    presence_penalty: 0.2 # Laisse peu d’innovation, focus sur structure
    max_tokens: 1500

  # Email Writer - Rédaction d'emails de candidature
  email_writer:
    provider: openai
    model: gpt-4o-mini
    temperature: 0.45 # Légère variation pour un ton humain
    top_p: 0.9 # Un peu de diversité dans la formulation
    frequency_penalty: 0.4 # Évite répétitions (« React », « IA »)
    presence_penalty: 0.3 # Encourage une reformulation légère
    max_tokens: 700

  # LinkedIn Writer - Messages LinkedIn personnalisés
  linkedin_writer:
    provider: openai
    model: gpt-4o-mini
    temperature: 0.55 # Laisse de la personnalité dans le ton
    top_p: 0.92 # Diversité légère pour formuler différemment
    frequency_penalty: 0.3 # Évite redondance
    presence_penalty: 0.5 # Encourage variation et spontanéité
    max_tokens: 350

  # Letter Writer - Lettres de motivation complètes
  letter_writer:
    provider: openai
    model: gpt-4o-mini
    temperature: 0.35 # Léger dynamisme sans perte de structure
    top_p: 0.9 # Diversité modérée pour éviter monotonie
    frequency_penalty: 0.5 # Réduit répétition des phrases d’accroche
    presence_penalty: 0.3 # Laisse place à un ton fluide
    max_tokens: 900
# Configuration par défaut si agent non spécifié
default:
  provider: openai
  model: gpt-4o-mini
  temperature: 0.45 # Légère variation pour un ton humain
  top_p: 0.9 # Un peu de diversité dans la formulation
  frequency_penalty: 0.4 # Évite répétitions (« React », « IA »)
  presence_penalty: 0.3 # Encourage une reformulation légère
  max_tokens: 700
#
# temperature: 0.0-2.0
#   - 0.0-0.3: Déterministe, factuel (extraction, analyse)
#   - 0.4-0.7: Équilibré (usage général)
#   - 0.8-1.2: Créatif (génération contenu)
#   - 1.3-2.0: Très créatif (brainstorming)
#
# max_tokens / max_output_tokens:
#   - Nombre maximum de tokens générés
#   - Email: 800-1200
#   - LinkedIn: 600-1000
#   - Lettre: 2000-3000
#
# top_p: 0.0-1.0
#   - Nucleus sampling
#   - 0.9-0.95: Recommandé pour cohérence
#   - 1.0: Pas de filtrage
#
# top_k: 1-100 (Gemini uniquement)
#   - Nombre de tokens considérés
#   - 40: Valeur standard
#
# frequency_penalty: -2.0 to 2.0 (OpenAI uniquement)
#   - Pénalise les répétitions de tokens
#   - 0.0: Pas de pénalité
#   - 0.5-1.0: Réduit répétitions
#
# presence_penalty: -2.0 to 2.0 (OpenAI uniquement)
#   - Encourage nouveaux sujets
#   - 0.0: Pas de pénalité
#   - 0.5-1.0: Encourage diversité
